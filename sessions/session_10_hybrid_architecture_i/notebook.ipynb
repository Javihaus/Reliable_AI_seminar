{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Session 10: Hybrid Architecture Design I\n",
    "## LLM + Symbolic Reasoning\n",
    "\n",
    "**Production LLM Deployment: Risk Characterization Before Failure**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Javihaus/Production_LLM_Deployment/blob/main/sessions/session_10_hybrid_architecture_i/notebook.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "**Learning Objectives:**\n",
    "1. Decide when hybrid architectures are necessary\n",
    "2. Design LLM + symbolic reasoning systems\n",
    "3. Implement temporal constraint checkers\n",
    "4. Specify component responsibilities clearly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q anthropic numpy pandas matplotlib seaborn\n",
    "\n",
    "import anthropic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "from enum import Enum\n",
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "import time\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    api_key = userdata.get('ANTHROPIC_API_KEY')\n",
    "except:\n",
    "    import os\n",
    "    api_key = os.environ.get('ANTHROPIC_API_KEY')\n",
    "\n",
    "client = anthropic.Anthropic(api_key=api_key)\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Part 1: When Are Hybrid Architectures Necessary?\n",
    "\n",
    "Based on our failure mode analysis, hybrid architectures are required when:\n",
    "\n",
    "| Requirement | Why LLM-Only Fails | Hybrid Solution |\n",
    "|-------------|-------------------|------------------|\n",
    "| Deterministic outputs | LLMs are probabilistic | Add verification module |\n",
    "| Temporal reasoning | Discrete tokens fail | Add temporal checker |\n",
    "| Constraint satisfaction | Approximation only | Add constraint solver |\n",
    "| Verifiable reasoning | Black box | Add symbolic reasoner |\n",
    "| Factual accuracy | Hallucination risk | Add retrieval (RAG) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridDecisionFramework:\n",
    "    \"\"\"Framework for deciding when hybrid architectures are needed.\"\"\"\n",
    "    \n",
    "    DECISION_CRITERIA = {\n",
    "        \"temporal_reasoning\": {\n",
    "            \"question\": \"Does your application require temporal constraint checking?\",\n",
    "            \"examples\": [\"medication timing\", \"scheduling\", \"deadlines\"],\n",
    "            \"llm_reliability\": \"VERY LOW\",\n",
    "            \"hybrid_component\": \"Temporal Constraint Checker\"\n",
    "        },\n",
    "        \"deterministic_output\": {\n",
    "            \"question\": \"Must outputs be deterministic and reproducible?\",\n",
    "            \"examples\": [\"compliance checking\", \"safety decisions\", \"financial calculations\"],\n",
    "            \"llm_reliability\": \"LOW\",\n",
    "            \"hybrid_component\": \"Verification Module\"\n",
    "        },\n",
    "        \"constraint_satisfaction\": {\n",
    "            \"question\": \"Are there hard constraints that must always be satisfied?\",\n",
    "            \"examples\": [\"resource allocation\", \"scheduling conflicts\", \"rule compliance\"],\n",
    "            \"llm_reliability\": \"LOW\",\n",
    "            \"hybrid_component\": \"Constraint Solver\"\n",
    "        },\n",
    "        \"factual_accuracy\": {\n",
    "            \"question\": \"Is factual accuracy critical with low tolerance for hallucination?\",\n",
    "            \"examples\": [\"medical information\", \"legal citations\", \"technical specifications\"],\n",
    "            \"llm_reliability\": \"MEDIUM\",\n",
    "            \"hybrid_component\": \"Retrieval-Augmented Generation (RAG)\"\n",
    "        },\n",
    "        \"audit_requirements\": {\n",
    "            \"question\": \"Must reasoning steps be traceable and auditable?\",\n",
    "            \"examples\": [\"regulatory compliance\", \"legal decisions\", \"financial audits\"],\n",
    "            \"llm_reliability\": \"LOW\",\n",
    "            \"hybrid_component\": \"Symbolic Reasoner with Logging\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def assess(self, requirements: List[str]) -> Dict:\n",
    "        \"\"\"Assess whether hybrid architecture is needed.\"\"\"\n",
    "        applicable = []\n",
    "        components_needed = []\n",
    "        \n",
    "        for req in requirements:\n",
    "            if req in self.DECISION_CRITERIA:\n",
    "                criteria = self.DECISION_CRITERIA[req]\n",
    "                applicable.append({\n",
    "                    \"requirement\": req,\n",
    "                    \"llm_reliability\": criteria[\"llm_reliability\"],\n",
    "                    \"component\": criteria[\"hybrid_component\"]\n",
    "                })\n",
    "                components_needed.append(criteria[\"hybrid_component\"])\n",
    "        \n",
    "        hybrid_needed = any(\n",
    "            c[\"llm_reliability\"] in [\"VERY LOW\", \"LOW\"] \n",
    "            for c in applicable\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"hybrid_needed\": hybrid_needed,\n",
    "            \"applicable_criteria\": applicable,\n",
    "            \"components_needed\": list(set(components_needed)),\n",
    "            \"recommendation\": self._get_recommendation(hybrid_needed, applicable)\n",
    "        }\n",
    "    \n",
    "    def _get_recommendation(self, hybrid_needed: bool, applicable: List) -> str:\n",
    "        if not hybrid_needed:\n",
    "            return \"Pure LLM approach may be sufficient. Proceed with careful testing.\"\n",
    "        \n",
    "        low_reliability = [a for a in applicable if a[\"llm_reliability\"] in [\"VERY LOW\", \"LOW\"]]\n",
    "        components = [a[\"component\"] for a in low_reliability]\n",
    "        \n",
    "        return f\"Hybrid architecture required. Add: {', '.join(set(components))}\"\n",
    "\n",
    "\n",
    "# Example: Medical triage system\n",
    "framework = HybridDecisionFramework()\n",
    "\n",
    "assessment = framework.assess([\n",
    "    \"temporal_reasoning\",\n",
    "    \"deterministic_output\",\n",
    "    \"factual_accuracy\"\n",
    "])\n",
    "\n",
    "print(\"HYBRID ARCHITECTURE ASSESSMENT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Hybrid Needed: {assessment['hybrid_needed']}\")\n",
    "print(f\"\\nComponents Needed:\")\n",
    "for comp in assessment['components_needed']:\n",
    "    print(f\"  - {comp}\")\n",
    "print(f\"\\nRecommendation: {assessment['recommendation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Part 2: Architecture Pattern 1 - LLM + Temporal Constraint Checker\n",
    "\n",
    "The most common hybrid pattern for medical and scheduling applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base classes for hybrid components\n",
    "\n",
    "class SymbolicChecker(ABC):\n",
    "    \"\"\"Abstract base class for symbolic checking modules.\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def validate(self, extracted_data: Dict) -> Dict:\n",
    "        \"\"\"Validate extracted data and return result.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ValidationResult:\n",
    "    \"\"\"Result of symbolic validation.\"\"\"\n",
    "    is_valid: bool\n",
    "    explanation: str\n",
    "    violations: List[str]\n",
    "    confidence: float = 1.0  # Symbolic = always 1.0\n",
    "\n",
    "\n",
    "class TemporalConstraintChecker(SymbolicChecker):\n",
    "    \"\"\"Deterministic temporal constraint validation.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.constraints = []\n",
    "    \n",
    "    def add_constraint(self, name: str, min_hours: float):\n",
    "        \"\"\"Add a minimum time gap constraint.\"\"\"\n",
    "        self.constraints.append({\"name\": name, \"min_hours\": min_hours})\n",
    "    \n",
    "    def _time_to_minutes(self, time_str: str) -> float:\n",
    "        \"\"\"Convert time string to minutes from midnight.\"\"\"\n",
    "        time_str = time_str.upper().strip()\n",
    "        is_pm = 'PM' in time_str\n",
    "        is_am = 'AM' in time_str\n",
    "        time_str = time_str.replace('AM', '').replace('PM', '').strip()\n",
    "        \n",
    "        parts = time_str.replace(':', ' ').split()\n",
    "        hours = int(parts[0])\n",
    "        minutes = int(parts[1]) if len(parts) > 1 else 0\n",
    "        \n",
    "        if is_pm and hours != 12:\n",
    "            hours += 12\n",
    "        elif is_am and hours == 12:\n",
    "            hours = 0\n",
    "        \n",
    "        return hours * 60 + minutes\n",
    "    \n",
    "    def validate(self, extracted_data: Dict) -> ValidationResult:\n",
    "        \"\"\"Validate temporal constraints.\"\"\"\n",
    "        violations = []\n",
    "        \n",
    "        event_a_time = self._time_to_minutes(extracted_data.get('event_a_time', '0:00'))\n",
    "        event_b_time = self._time_to_minutes(extracted_data.get('event_b_time', '0:00'))\n",
    "        min_gap_hours = extracted_data.get('min_gap_hours', 0)\n",
    "        \n",
    "        elapsed_minutes = event_b_time - event_a_time\n",
    "        required_minutes = min_gap_hours * 60\n",
    "        \n",
    "        is_valid = elapsed_minutes >= required_minutes\n",
    "        \n",
    "        if not is_valid:\n",
    "            violations.append(\n",
    "                f\"Insufficient time gap: {elapsed_minutes/60:.2f}h elapsed, \"\n",
    "                f\"{min_gap_hours}h required\"\n",
    "            )\n",
    "        \n",
    "        explanation = (\n",
    "            f\"Time elapsed: {elapsed_minutes/60:.2f} hours. \"\n",
    "            f\"Required: {min_gap_hours} hours. \"\n",
    "            f\"{'VALID' if is_valid else 'INVALID'}\"\n",
    "        )\n",
    "        \n",
    "        return ValidationResult(\n",
    "            is_valid=is_valid,\n",
    "            explanation=explanation,\n",
    "            violations=violations\n",
    "        )\n",
    "\n",
    "\n",
    "# Test the checker\n",
    "checker = TemporalConstraintChecker()\n",
    "\n",
    "test_data = {\n",
    "    'event_a_time': '8:00 AM',\n",
    "    'event_b_time': '11:00 AM',\n",
    "    'min_gap_hours': 4\n",
    "}\n",
    "\n",
    "result = checker.validate(test_data)\n",
    "print(f\"Valid: {result.is_valid}\")\n",
    "print(f\"Explanation: {result.explanation}\")\n",
    "print(f\"Violations: {result.violations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMExtractor:\n",
    "    \"\"\"LLM component for extracting structured information from natural language.\"\"\"\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "    \n",
    "    def extract_temporal_info(self, scenario: str) -> Optional[Dict]:\n",
    "        \"\"\"Extract temporal information from natural language.\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"Extract the temporal information from this scenario.\n",
    "Return ONLY a JSON object with these exact fields:\n",
    "- event_a_time: time of first event (format: \"HH:MM AM/PM\")\n",
    "- event_b_time: time of second event (format: \"HH:MM AM/PM\")\n",
    "- min_gap_hours: minimum required gap in hours (number)\n",
    "\n",
    "Scenario: {scenario}\n",
    "\n",
    "JSON:\"\"\"\n",
    "        \n",
    "        response = self.client.messages.create(\n",
    "            model=\"claude-sonnet-4-5-20250929\",\n",
    "            max_tokens=200,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        text = response.content[0].text\n",
    "        \n",
    "        # Parse JSON from response\n",
    "        start = text.find('{')\n",
    "        end = text.rfind('}') + 1\n",
    "        if start >= 0 and end > start:\n",
    "            try:\n",
    "                return json.loads(text[start:end])\n",
    "            except json.JSONDecodeError:\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "\n",
    "# Test extraction\n",
    "extractor = LLMExtractor(client)\n",
    "\n",
    "scenario = \"I took aspirin at 8:00 AM. The doctor said to wait at least 4 hours before taking ibuprofen. It's now 11:00 AM - can I take it?\"\n",
    "\n",
    "extracted = extractor.extract_temporal_info(scenario)\n",
    "print(\"Extracted information:\")\n",
    "print(json.dumps(extracted, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridTemporalReasoner:\n",
    "    \"\"\"Complete hybrid system combining LLM extraction with symbolic verification.\"\"\"\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.extractor = LLMExtractor(client)\n",
    "        self.checker = TemporalConstraintChecker()\n",
    "    \n",
    "    def reason(self, natural_language_input: str) -> Dict:\n",
    "        \"\"\"Full hybrid reasoning pipeline.\"\"\"\n",
    "        \n",
    "        # Step 1: LLM extracts structured information\n",
    "        extracted = self.extractor.extract_temporal_info(natural_language_input)\n",
    "        \n",
    "        if not extracted:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"Could not extract temporal information from input\",\n",
    "                \"input\": natural_language_input\n",
    "            }\n",
    "        \n",
    "        # Step 2: Symbolic checker validates constraints\n",
    "        validation = self.checker.validate(extracted)\n",
    "        \n",
    "        # Step 3: Return combined result\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"input\": natural_language_input,\n",
    "            \"extracted\": extracted,\n",
    "            \"is_valid\": validation.is_valid,\n",
    "            \"answer\": \"YES\" if validation.is_valid else \"NO\",\n",
    "            \"explanation\": validation.explanation,\n",
    "            \"violations\": validation.violations,\n",
    "            \"confidence\": validation.confidence\n",
    "        }\n",
    "\n",
    "\n",
    "# Test the complete hybrid system\n",
    "hybrid = HybridTemporalReasoner(client)\n",
    "\n",
    "test_scenarios = [\n",
    "    \"I took my blood pressure medication at 7:30 AM. The pharmacist said to wait at least 6 hours before taking the antihistamine. It's now 1:00 PM - is it safe?\",\n",
    "    \"Patient received Drug A at 9:00 AM. Protocol requires 4-hour separation before Drug B. Current time: 12:45 PM. Should we administer Drug B?\",\n",
    "    \"The morning dose was given at 6:00 AM. Evening dose requires minimum 8 hours gap. Can we give it at 3:00 PM?\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"HYBRID TEMPORAL REASONER - TEST RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for scenario in test_scenarios:\n",
    "    print(f\"\\nScenario: {scenario[:60]}...\")\n",
    "    result = hybrid.reason(scenario)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        print(f\"Extracted: {result['extracted']}\")\n",
    "        print(f\"Answer: {result['answer']}\")\n",
    "        print(f\"Explanation: {result['explanation']}\")\n",
    "    else:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Part 3: Architecture Pattern 2 - LLM + Verification Module\n",
    "\n",
    "For applications requiring post-hoc verification of LLM outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplianceVerifier(SymbolicChecker):\n",
    "    \"\"\"Verifies LLM outputs against compliance rules.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rules = []\n",
    "    \n",
    "    def add_rule(self, name: str, check_fn, error_msg: str):\n",
    "        \"\"\"Add a compliance rule.\"\"\"\n",
    "        self.rules.append({\n",
    "            \"name\": name,\n",
    "            \"check\": check_fn,\n",
    "            \"error_msg\": error_msg\n",
    "        })\n",
    "    \n",
    "    def validate(self, extracted_data: Dict) -> ValidationResult:\n",
    "        \"\"\"Validate against all compliance rules.\"\"\"\n",
    "        violations = []\n",
    "        \n",
    "        for rule in self.rules:\n",
    "            if not rule[\"check\"](extracted_data):\n",
    "                violations.append(f\"{rule['name']}: {rule['error_msg']}\")\n",
    "        \n",
    "        is_valid = len(violations) == 0\n",
    "        \n",
    "        return ValidationResult(\n",
    "            is_valid=is_valid,\n",
    "            explanation=f\"Passed {len(self.rules) - len(violations)}/{len(self.rules)} rules\",\n",
    "            violations=violations\n",
    "        )\n",
    "\n",
    "\n",
    "class HybridComplianceSystem:\n",
    "    \"\"\"Hybrid system for compliance checking.\"\"\"\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.verifier = ComplianceVerifier()\n",
    "        self._setup_rules()\n",
    "    \n",
    "    def _setup_rules(self):\n",
    "        \"\"\"Set up compliance rules.\"\"\"\n",
    "        # Rule 1: Amount must be positive\n",
    "        self.verifier.add_rule(\n",
    "            \"positive_amount\",\n",
    "            lambda d: d.get('amount', 0) > 0,\n",
    "            \"Amount must be positive\"\n",
    "        )\n",
    "        \n",
    "        # Rule 2: Amount must be within limit\n",
    "        self.verifier.add_rule(\n",
    "            \"amount_limit\",\n",
    "            lambda d: d.get('amount', 0) <= 10000,\n",
    "            \"Amount exceeds $10,000 limit\"\n",
    "        )\n",
    "        \n",
    "        # Rule 3: Must have approval for large amounts\n",
    "        self.verifier.add_rule(\n",
    "            \"approval_required\",\n",
    "            lambda d: d.get('amount', 0) <= 5000 or d.get('has_approval', False),\n",
    "            \"Amounts over $5,000 require approval\"\n",
    "        )\n",
    "    \n",
    "    def extract_transaction_info(self, text: str) -> Optional[Dict]:\n",
    "        \"\"\"Use LLM to extract transaction information.\"\"\"\n",
    "        prompt = f\"\"\"Extract the transaction information from this text.\n",
    "Return ONLY a JSON object with:\n",
    "- amount: the dollar amount (number)\n",
    "- has_approval: whether approval was mentioned (boolean)\n",
    "- description: brief description of transaction\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "JSON:\"\"\"\n",
    "        \n",
    "        response = self.client.messages.create(\n",
    "            model=\"claude-sonnet-4-5-20250929\",\n",
    "            max_tokens=200,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        text_response = response.content[0].text\n",
    "        start = text_response.find('{')\n",
    "        end = text_response.rfind('}') + 1\n",
    "        \n",
    "        if start >= 0 and end > start:\n",
    "            try:\n",
    "                return json.loads(text_response[start:end])\n",
    "            except json.JSONDecodeError:\n",
    "                return None\n",
    "        return None\n",
    "    \n",
    "    def process(self, transaction_text: str) -> Dict:\n",
    "        \"\"\"Process transaction through hybrid pipeline.\"\"\"\n",
    "        # Step 1: LLM extracts information\n",
    "        extracted = self.extract_transaction_info(transaction_text)\n",
    "        \n",
    "        if not extracted:\n",
    "            return {\"success\": False, \"error\": \"Could not extract transaction info\"}\n",
    "        \n",
    "        # Step 2: Verify against rules\n",
    "        validation = self.verifier.validate(extracted)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"extracted\": extracted,\n",
    "            \"compliant\": validation.is_valid,\n",
    "            \"explanation\": validation.explanation,\n",
    "            \"violations\": validation.violations\n",
    "        }\n",
    "\n",
    "\n",
    "# Test the compliance system\n",
    "compliance_system = HybridComplianceSystem(client)\n",
    "\n",
    "test_transactions = [\n",
    "    \"Process a payment of $3,500 for office supplies.\",\n",
    "    \"Transfer $7,500 to vendor. Manager approval obtained.\",\n",
    "    \"Reimbursement request for $8,000 conference expenses. No approval yet.\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPLIANCE VERIFICATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for transaction in test_transactions:\n",
    "    print(f\"\\nTransaction: {transaction}\")\n",
    "    result = compliance_system.process(transaction)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        print(f\"Extracted: {result['extracted']}\")\n",
    "        print(f\"Compliant: {result['compliant']}\")\n",
    "        if result['violations']:\n",
    "            print(f\"Violations: {result['violations']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Part 4: Architecture Pattern 3 - LLM + Retrieval (RAG)\n",
    "\n",
    "For applications requiring factual grounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"Simple in-memory vector store for demonstration.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "    \n",
    "    def add_document(self, doc_id: str, content: str, metadata: Dict = None):\n",
    "        \"\"\"Add a document to the store.\"\"\"\n",
    "        self.documents.append({\n",
    "            \"id\": doc_id,\n",
    "            \"content\": content,\n",
    "            \"metadata\": metadata or {}\n",
    "        })\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"Simple keyword-based search (placeholder for vector search).\"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        \n",
    "        scored = []\n",
    "        for doc in self.documents:\n",
    "            doc_words = set(doc[\"content\"].lower().split())\n",
    "            overlap = len(query_words & doc_words)\n",
    "            scored.append((overlap, doc))\n",
    "        \n",
    "        scored.sort(key=lambda x: x[0], reverse=True)\n",
    "        return [doc for _, doc in scored[:top_k]]\n",
    "\n",
    "\n",
    "class HybridRAGSystem:\n",
    "    \"\"\"Hybrid RAG system with retrieval grounding.\"\"\"\n",
    "    \n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.vector_store = SimpleVectorStore()\n",
    "        self._load_knowledge_base()\n",
    "    \n",
    "    def _load_knowledge_base(self):\n",
    "        \"\"\"Load sample knowledge base.\"\"\"\n",
    "        docs = [\n",
    "            (\"med_001\", \"Aspirin should not be taken with ibuprofen within 4 hours. Both are NSAIDs and can increase bleeding risk.\"),\n",
    "            (\"med_002\", \"Acetaminophen (Tylenol) can be taken with NSAIDs as they work differently.\"),\n",
    "            (\"med_003\", \"Blood pressure medications should be taken at the same time each day for consistent effect.\"),\n",
    "            (\"med_004\", \"Antihistamines may cause drowsiness. Avoid driving until you know how they affect you.\"),\n",
    "            (\"med_005\", \"Grapefruit juice can interact with many medications. Consult your pharmacist.\")\n",
    "        ]\n",
    "        \n",
    "        for doc_id, content in docs:\n",
    "            self.vector_store.add_document(doc_id, content)\n",
    "    \n",
    "    def answer(self, question: str) -> Dict:\n",
    "        \"\"\"Answer question using RAG.\"\"\"\n",
    "        # Step 1: Retrieve relevant documents\n",
    "        retrieved = self.vector_store.search(question, top_k=2)\n",
    "        \n",
    "        context = \"\\n\".join([f\"- {doc['content']}\" for doc in retrieved])\n",
    "        \n",
    "        # Step 2: Generate answer with context\n",
    "        prompt = f\"\"\"Answer the question based ONLY on the provided context.\n",
    "If the context doesn't contain enough information, say \"I don't have enough information.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        response = self.client.messages.create(\n",
    "            model=\"claude-sonnet-4-5-20250929\",\n",
    "            max_tokens=300,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": response.content[0].text,\n",
    "            \"sources\": [doc[\"id\"] for doc in retrieved],\n",
    "            \"context_used\": context\n",
    "        }\n",
    "\n",
    "\n",
    "# Test RAG system\n",
    "rag_system = HybridRAGSystem(client)\n",
    "\n",
    "questions = [\n",
    "    \"Can I take aspirin and ibuprofen together?\",\n",
    "    \"Is it safe to take Tylenol with other pain medications?\",\n",
    "    \"What should I know about antihistamines?\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RAG SYSTEM - GROUNDED ANSWERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    result = rag_system.answer(question)\n",
    "    print(f\"A: {result['answer'][:200]}...\")\n",
    "    print(f\"Sources: {result['sources']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Part 5: Component Responsibility Matrix\n",
    "\n",
    "Clear separation of concerns is critical for hybrid architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create responsibility matrix visualization\n",
    "\n",
    "responsibilities = {\n",
    "    \"Task\": [\n",
    "        \"Natural language understanding\",\n",
    "        \"Entity extraction\",\n",
    "        \"Temporal math\",\n",
    "        \"Constraint propagation\",\n",
    "        \"Deterministic validation\",\n",
    "        \"Human-readable explanations\",\n",
    "        \"Ambiguity resolution\",\n",
    "        \"Consistency checking\",\n",
    "        \"Audit logging\"\n",
    "    ],\n",
    "    \"LLM\": [1, 1, 0, 0, 0, 1, 1, 0, 0],\n",
    "    \"Symbolic\": [0, 0, 1, 1, 1, 0, 0, 1, 1]\n",
    "}\n",
    "\n",
    "df_resp = pd.DataFrame(responsibilities)\n",
    "df_resp = df_resp.set_index(\"Task\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    df_resp, \n",
    "    annot=True, \n",
    "    cmap=[\"#FFCCCC\", \"#CCFFCC\"],\n",
    "    cbar=False,\n",
    "    linewidths=1,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(\"Component Responsibility Matrix\\n(1 = Responsible, 0 = Not Responsible)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Part 6: Exercise - Design Your Hybrid Architecture\n",
    "\n",
    "Apply the patterns to your deployment scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Fill in your hybrid architecture specification\n",
    "\n",
    "class HybridArchitectureSpec:\n",
    "    \"\"\"Template for specifying hybrid architecture.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"YOUR APPLICATION NAME\"\n",
    "        self.llm_responsibilities = []\n",
    "        self.symbolic_responsibilities = []\n",
    "        self.data_flow = []\n",
    "        self.error_handling = []\n",
    "    \n",
    "    def add_llm_responsibility(self, task: str):\n",
    "        self.llm_responsibilities.append(task)\n",
    "    \n",
    "    def add_symbolic_responsibility(self, task: str):\n",
    "        self.symbolic_responsibilities.append(task)\n",
    "    \n",
    "    def add_data_flow_step(self, step: str):\n",
    "        self.data_flow.append(step)\n",
    "    \n",
    "    def add_error_handler(self, error_type: str, handler: str):\n",
    "        self.error_handling.append({\"error\": error_type, \"handler\": handler})\n",
    "    \n",
    "    def print_spec(self):\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"HYBRID ARCHITECTURE: {self.name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(\"\\nLLM Responsibilities:\")\n",
    "        for r in self.llm_responsibilities:\n",
    "            print(f\"  - {r}\")\n",
    "        \n",
    "        print(\"\\nSymbolic Component Responsibilities:\")\n",
    "        for r in self.symbolic_responsibilities:\n",
    "            print(f\"  - {r}\")\n",
    "        \n",
    "        print(\"\\nData Flow:\")\n",
    "        for i, step in enumerate(self.data_flow, 1):\n",
    "            print(f\"  {i}. {step}\")\n",
    "        \n",
    "        print(\"\\nError Handling:\")\n",
    "        for eh in self.error_handling:\n",
    "            print(f\"  - {eh['error']}: {eh['handler']}\")\n",
    "\n",
    "\n",
    "# Example specification\n",
    "spec = HybridArchitectureSpec()\n",
    "spec.name = \"Medical Appointment Scheduler\"\n",
    "\n",
    "spec.add_llm_responsibility(\"Parse natural language appointment requests\")\n",
    "spec.add_llm_responsibility(\"Extract patient preferences\")\n",
    "spec.add_llm_responsibility(\"Generate human-friendly confirmation messages\")\n",
    "\n",
    "spec.add_symbolic_responsibility(\"Check schedule conflicts\")\n",
    "spec.add_symbolic_responsibility(\"Enforce appointment duration rules\")\n",
    "spec.add_symbolic_responsibility(\"Validate buffer times between appointments\")\n",
    "\n",
    "spec.add_data_flow_step(\"User request -> LLM (extract appointment details)\")\n",
    "spec.add_data_flow_step(\"Extracted details -> Constraint Checker (validate schedule)\")\n",
    "spec.add_data_flow_step(\"If valid: Confirm booking\")\n",
    "spec.add_data_flow_step(\"If invalid: Return alternatives\")\n",
    "\n",
    "spec.add_error_handler(\"Extraction failure\", \"Ask user for clarification\")\n",
    "spec.add_error_handler(\"Schedule conflict\", \"Suggest nearest available times\")\n",
    "\n",
    "spec.print_spec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Know when hybrid is necessary** - Use the decision framework to assess your requirements\n",
    "\n",
    "2. **Clear responsibility separation** - LLM handles language, symbolic handles logic\n",
    "\n",
    "3. **Three main patterns:**\n",
    "   - LLM + Temporal Checker (scheduling, timing)\n",
    "   - LLM + Verifier (compliance, safety)\n",
    "   - LLM + Retrieval (factual grounding)\n",
    "\n",
    "4. **Design for failure** - Plan error handling at each interface\n",
    "\n",
    "5. **Test the whole system** - Integration testing is critical\n",
    "\n",
    "---\n",
    "\n",
    "**Homework:** Design a complete hybrid architecture specification for your deployment scenario.\n",
    "\n",
    "**Next Session:** Hybrid Architecture Design II - Integration Patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
