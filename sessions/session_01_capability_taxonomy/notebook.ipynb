{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1: Capability Taxonomy\n",
    "## What LLMs Can and Cannot Reliably Do\n",
    "\n",
    "**Production LLM Deployment: Risk Characterization Before Failure**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Javihaus/Production_LLM_Deployment/blob/main/sessions/session_01_capability_taxonomy/notebook.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "**Learning Objectives:**\n",
    "1. Understand the six capability classes for LLM task classification\n",
    "2. Identify architectural prerequisites for each capability class\n",
    "3. Apply the classification framework to real deployment scenarios\n",
    "4. Determine when hybrid architectures are necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q anthropic langchain langgraph langchain-anthropic\n",
    "!pip install -q numpy pandas matplotlib seaborn\n",
    "\n",
    "import anthropic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Get API key\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    api_key = userdata.get('ANTHROPIC_API_KEY')\n",
    "except:\n",
    "    import os\n",
    "    api_key = os.environ.get('ANTHROPIC_API_KEY')\n",
    "\n",
    "client = anthropic.Anthropic(api_key=api_key)\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The Six Capability Classes\n",
    "\n",
    "We define six capability classes based on what architectural mechanisms they require:\n",
    "\n",
    "| Class | Description | LLM Reliability |\n",
    "|-------|-------------|----------------|\n",
    "| Pattern Completion | High-probability text continuations | HIGH |\n",
    "| Knowledge Retrieval | Recall of training data facts | MEDIUM |\n",
    "| Compositional Reasoning | Systematic combination of primitives | LOW |\n",
    "| Continuous State | Maintenance of evolving quantities | VERY LOW |\n",
    "| Constraint Satisfaction | Simultaneous hard constraint handling | LOW |\n",
    "| Interactive Collaboration | Real-time human interaction | MEDIUM (latency-dependent) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Demonstrating Capability Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pattern Completion (HIGH Reliability)\n",
    "\n",
    "Tasks where the model continues patterns seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pattern_completion():\n",
    "    \"\"\"Test pattern completion capability - should work reliably.\"\"\"\n",
    "    \n",
    "    prompts = [\n",
    "        \"Complete this Python function:\\ndef fibonacci(n):\\n    if n <= 1:\\n        return n\\n    return\",\n",
    "        \"Summarize in one sentence: The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet.\",\n",
    "        \"Translate to French: Hello, how are you today?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"PATTERN COMPLETION TESTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, prompt in enumerate(prompts, 1):\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-sonnet-4-5-20250929\",\n",
    "            max_tokens=150,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        print(f\"\\nTest {i}:\")\n",
    "        print(f\"Prompt: {prompt[:50]}...\")\n",
    "        print(f\"Response: {response.content[0].text[:200]}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "test_pattern_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Compositional Reasoning (LOW Reliability)\n",
    "\n",
    "Tasks requiring systematic combination of learned primitives in novel ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compositional_reasoning():\n",
    "    \"\"\"Test compositional reasoning - expect inconsistent results.\"\"\"\n",
    "    \n",
    "    # Lake & Baroni style compositional tests\n",
    "    prompts = [\n",
    "        # Novel composition of known primitives\n",
    "        \"\"\"If 'dax' means 'jump twice' and 'wif' means 'turn left', \n",
    "        what does 'dax wif dax' mean? Describe the sequence of actions.\"\"\",\n",
    "        \n",
    "        # Multi-step logical reasoning\n",
    "        \"\"\"A is bigger than B. B is bigger than C. C is bigger than D.\n",
    "        E is bigger than A. F is smaller than D.\n",
    "        List all items from biggest to smallest.\"\"\",\n",
    "        \n",
    "        # Novel algorithm application\n",
    "        \"\"\"Apply this sorting rule to [5, 2, 8, 1, 9]:\n",
    "        - Compare adjacent pairs\n",
    "        - If left > right, swap them\n",
    "        - Repeat until no swaps needed\n",
    "        Show each step.\"\"\"\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"COMPOSITIONAL REASONING TESTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    for i, prompt in enumerate(prompts, 1):\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-sonnet-4-5-20250929\",\n",
    "            max_tokens=500,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        print(f\"\\nTest {i}:\")\n",
    "        print(f\"Prompt: {prompt[:60]}...\")\n",
    "        print(f\"Response:\\n{response.content[0].text}\")\n",
    "        print(\"-\" * 40)\n",
    "        results.append(response.content[0].text)\n",
    "    \n",
    "    return results\n",
    "\n",
    "comp_results = test_compositional_reasoning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Continuous State Representation (VERY LOW Reliability)\n",
    "\n",
    "Tasks requiring maintenance of continuous quantities over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_temporal_reasoning():\n",
    "    \"\"\"Test temporal/continuous state reasoning - expect failures.\"\"\"\n",
    "    \n",
    "    scenarios = [\n",
    "        {\n",
    "            \"prompt\": \"\"\"A patient takes medication A at 8:00 AM. \n",
    "            Medication A must be taken at least 4 hours before medication B.\n",
    "            Can the patient take medication B at 11:30 AM?\n",
    "            Answer only YES or NO, then explain.\"\"\",\n",
    "            \"correct\": \"NO\",\n",
    "            \"reason\": \"11:30 AM is only 3.5 hours after 8:00 AM, not 4 hours\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"\"\"Meeting A runs from 2:00 PM to 3:30 PM.\n",
    "            Meeting B runs from 3:00 PM to 4:00 PM.\n",
    "            Do these meetings overlap?\n",
    "            Answer only YES or NO, then explain.\"\"\",\n",
    "            \"correct\": \"YES\",\n",
    "            \"reason\": \"They overlap from 3:00 PM to 3:30 PM\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"\"\"A train departs at 9:15 AM and travels for 2 hours 45 minutes.\n",
    "            What time does it arrive?\n",
    "            Give only the arrival time.\"\"\",\n",
    "            \"correct\": \"12:00 PM\",\n",
    "            \"reason\": \"9:15 + 2:45 = 12:00\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"TEMPORAL REASONING TESTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    for i, scenario in enumerate(scenarios, 1):\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-sonnet-4-5-20250929\",\n",
    "            max_tokens=200,\n",
    "            messages=[{\"role\": \"user\", \"content\": scenario[\"prompt\"]}]\n",
    "        )\n",
    "        \n",
    "        answer = response.content[0].text\n",
    "        correct = scenario[\"correct\"].lower() in answer.lower()[:20]\n",
    "        \n",
    "        print(f\"\\nTest {i}:\")\n",
    "        print(f\"Scenario: {scenario['prompt'][:60]}...\")\n",
    "        print(f\"Expected: {scenario['correct']}\")\n",
    "        print(f\"Response: {answer[:150]}\")\n",
    "        print(f\"Correct: {'YES' if correct else 'NO'}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        results.append({\n",
    "            \"test\": i,\n",
    "            \"correct\": correct,\n",
    "            \"expected\": scenario[\"correct\"],\n",
    "            \"response\": answer\n",
    "        })\n",
    "    \n",
    "    accuracy = sum(r[\"correct\"] for r in results) / len(results)\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.1%}\")\n",
    "    return results\n",
    "\n",
    "temporal_results = test_temporal_reasoning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Measuring Brittleness\n",
    "\n",
    "A key diagnostic for whether LLMs are pattern matching vs. truly understanding is **brittleness**: how much does accuracy change when we vary prompt format while keeping semantic content identical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_brittleness():\n",
    "    \"\"\"Measure accuracy changes across prompt format variations.\"\"\"\n",
    "    \n",
    "    # Same semantic content, different formats\n",
    "    base_scenario = {\n",
    "        \"content\": \"Patient took aspirin at 8 AM. Must wait 4 hours before ibuprofen. Can take ibuprofen at 11 AM?\",\n",
    "        \"correct\": \"NO\"  # Only 3 hours have passed\n",
    "    }\n",
    "    \n",
    "    prompt_formats = [\n",
    "        # Format 1: Direct question\n",
    "        \"\"\"A patient took aspirin at 8:00 AM. They must wait at least 4 hours before taking ibuprofen. \n",
    "        Can they take ibuprofen at 11:00 AM? Answer YES or NO only.\"\"\",\n",
    "        \n",
    "        # Format 2: Clinical note style\n",
    "        \"\"\"CLINICAL NOTE\n",
    "        Medication administered: Aspirin @ 08:00\n",
    "        Required interval before ibuprofen: 4h minimum\n",
    "        Proposed ibuprofen time: 11:00\n",
    "        \n",
    "        Is proposed time acceptable? (YES/NO)\"\"\",\n",
    "        \n",
    "        # Format 3: Conversational\n",
    "        \"\"\"Hey, I took aspirin this morning at 8. The bottle says wait 4 hours before \n",
    "        taking ibuprofen. It's 11 now - am I good to take it? Just yes or no.\"\"\",\n",
    "        \n",
    "        # Format 4: Formal medical\n",
    "        \"\"\"Given: Acetylsalicylic acid (aspirin) administered at 0800 hours.\n",
    "        Constraint: Minimum 4-hour interval required before NSAID (ibuprofen) administration.\n",
    "        Query: Is ibuprofen administration at 1100 hours compliant with temporal constraint?\n",
    "        Response format: YES or NO\"\"\",\n",
    "        \n",
    "        # Format 5: JSON-style\n",
    "        \"\"\"{\n",
    "          \"medication_1\": {\"drug\": \"aspirin\", \"time\": \"8:00 AM\"},\n",
    "          \"constraint\": \"4 hours between aspirin and ibuprofen\",\n",
    "          \"medication_2\": {\"drug\": \"ibuprofen\", \"proposed_time\": \"11:00 AM\"}\n",
    "        }\n",
    "        Is the proposed time valid? Respond with only YES or NO.\"\"\"\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"BRITTLENESS TEST: Same scenario, different formats\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Correct answer for all formats: {base_scenario['correct']}\")\n",
    "    print(\"(8:00 AM + 3 hours = 11:00 AM, which is less than 4 hours)\\n\")\n",
    "    \n",
    "    results = []\n",
    "    for i, prompt in enumerate(prompt_formats, 1):\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-sonnet-4-5-20250929\",\n",
    "            max_tokens=50,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        answer = response.content[0].text.strip().upper()\n",
    "        # Extract YES or NO from response\n",
    "        if \"YES\" in answer[:10]:\n",
    "            extracted = \"YES\"\n",
    "        elif \"NO\" in answer[:10]:\n",
    "            extracted = \"NO\"\n",
    "        else:\n",
    "            extracted = \"UNCLEAR\"\n",
    "        \n",
    "        correct = extracted == base_scenario[\"correct\"]\n",
    "        \n",
    "        print(f\"Format {i}: {extracted} - {'CORRECT' if correct else 'WRONG'}\")\n",
    "        results.append({\"format\": i, \"response\": extracted, \"correct\": correct})\n",
    "        \n",
    "        time.sleep(0.5)  # Rate limiting\n",
    "    \n",
    "    accuracy = sum(r[\"correct\"] for r in results) / len(results)\n",
    "    print(f\"\\nAccuracy across formats: {accuracy:.1%}\")\n",
    "    print(f\"Brittleness indicator: {(1 - accuracy) * 100:.1f} percentage points variation\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "brittleness_results = measure_brittleness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Capability Classification Framework\n",
    "\n",
    "Use this framework to classify any deployment scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapabilityClassifier:\n",
    "    \"\"\"Framework for classifying LLM deployment scenarios.\"\"\"\n",
    "    \n",
    "    CLASSES = {\n",
    "        \"pattern_completion\": {\n",
    "            \"name\": \"Pattern Completion\",\n",
    "            \"reliability\": \"HIGH\",\n",
    "            \"hybrid_needed\": False,\n",
    "            \"examples\": [\"text completion\", \"summarization\", \"translation\", \"code completion\"]\n",
    "        },\n",
    "        \"knowledge_retrieval\": {\n",
    "            \"name\": \"Knowledge Retrieval\",\n",
    "            \"reliability\": \"MEDIUM\",\n",
    "            \"hybrid_needed\": \"Sometimes (RAG)\",\n",
    "            \"examples\": [\"factual Q&A\", \"concept explanation\", \"definitions\"]\n",
    "        },\n",
    "        \"compositional_reasoning\": {\n",
    "            \"name\": \"Compositional Reasoning\",\n",
    "            \"reliability\": \"LOW\",\n",
    "            \"hybrid_needed\": True,\n",
    "            \"examples\": [\"multi-step proofs\", \"novel algorithms\", \"logical deduction\"]\n",
    "        },\n",
    "        \"continuous_state\": {\n",
    "            \"name\": \"Continuous State Representation\",\n",
    "            \"reliability\": \"VERY LOW\",\n",
    "            \"hybrid_needed\": True,\n",
    "            \"examples\": [\"temporal constraints\", \"scheduling\", \"physical simulation\"]\n",
    "        },\n",
    "        \"constraint_satisfaction\": {\n",
    "            \"name\": \"Constraint Satisfaction\",\n",
    "            \"reliability\": \"LOW\",\n",
    "            \"hybrid_needed\": True,\n",
    "            \"examples\": [\"scheduling\", \"resource allocation\", \"compliance verification\"]\n",
    "        },\n",
    "        \"interactive_collaboration\": {\n",
    "            \"name\": \"Interactive Collaboration\",\n",
    "            \"reliability\": \"MEDIUM\",\n",
    "            \"hybrid_needed\": \"Latency-dependent\",\n",
    "            \"examples\": [\"pair programming\", \"collaborative writing\", \"real-time support\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.classification = {}\n",
    "        \n",
    "    def classify(self, scenario_name: str, required_classes: List[str]) -> Dict:\n",
    "        \"\"\"Classify a deployment scenario.\"\"\"\n",
    "        \n",
    "        self.classification = {\n",
    "            \"scenario\": scenario_name,\n",
    "            \"classes\": {},\n",
    "            \"weakest_link\": None,\n",
    "            \"hybrid_needed\": False,\n",
    "            \"testing_required\": []\n",
    "        }\n",
    "        \n",
    "        reliability_order = [\"VERY LOW\", \"LOW\", \"MEDIUM\", \"HIGH\"]\n",
    "        min_reliability = \"HIGH\"\n",
    "        \n",
    "        for class_key in required_classes:\n",
    "            if class_key in self.CLASSES:\n",
    "                class_info = self.CLASSES[class_key]\n",
    "                self.classification[\"classes\"][class_key] = class_info\n",
    "                \n",
    "                # Track weakest link\n",
    "                if reliability_order.index(class_info[\"reliability\"]) < reliability_order.index(min_reliability):\n",
    "                    min_reliability = class_info[\"reliability\"]\n",
    "                    self.classification[\"weakest_link\"] = class_key\n",
    "                \n",
    "                # Check if hybrid needed\n",
    "                if class_info[\"hybrid_needed\"] == True:\n",
    "                    self.classification[\"hybrid_needed\"] = True\n",
    "        \n",
    "        # Determine required testing\n",
    "        self._determine_testing()\n",
    "        \n",
    "        return self.classification\n",
    "    \n",
    "    def _determine_testing(self):\n",
    "        \"\"\"Determine required testing based on capability classes.\"\"\"\n",
    "        testing = []\n",
    "        \n",
    "        if \"continuous_state\" in self.classification[\"classes\"]:\n",
    "            testing.extend([\"Temporal constraint testing\", \"Allen's interval algebra validation\"])\n",
    "        \n",
    "        if \"compositional_reasoning\" in self.classification[\"classes\"]:\n",
    "            testing.extend([\"Compositional generalization tests\", \"Multi-step reasoning validation\"])\n",
    "        \n",
    "        if \"knowledge_retrieval\" in self.classification[\"classes\"]:\n",
    "            testing.extend([\"Hallucination detection\", \"Confidence calibration\"])\n",
    "        \n",
    "        if \"constraint_satisfaction\" in self.classification[\"classes\"]:\n",
    "            testing.extend([\"Constraint violation detection\", \"Edge case testing\"])\n",
    "        \n",
    "        if \"interactive_collaboration\" in self.classification[\"classes\"]:\n",
    "            testing.extend([\"Latency impact measurement\", \"Interaction bandwidth analysis\"])\n",
    "        \n",
    "        # Always include brittleness testing\n",
    "        testing.append(\"Multi-format brittleness testing\")\n",
    "        \n",
    "        self.classification[\"testing_required\"] = testing\n",
    "    \n",
    "    def print_report(self):\n",
    "        \"\"\"Print classification report.\"\"\"\n",
    "        c = self.classification\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(f\"CAPABILITY CLASSIFICATION: {c['scenario']}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(\"\\nRequired Capability Classes:\")\n",
    "        for key, info in c[\"classes\"].items():\n",
    "            print(f\"  - {info['name']}: Reliability = {info['reliability']}\")\n",
    "        \n",
    "        print(f\"\\nWeakest Link: {self.CLASSES[c['weakest_link']]['name'] if c['weakest_link'] else 'N/A'}\")\n",
    "        print(f\"Hybrid Architecture Needed: {'YES' if c['hybrid_needed'] else 'NO'}\")\n",
    "        \n",
    "        print(\"\\nRequired Testing:\")\n",
    "        for test in c[\"testing_required\"]:\n",
    "            print(f\"  - {test}\")\n",
    "        \n",
    "        print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Medical Triage Chatbot\n",
    "classifier = CapabilityClassifier()\n",
    "\n",
    "classification = classifier.classify(\n",
    "    scenario_name=\"Medical Symptom Triage Chatbot\",\n",
    "    required_classes=[\n",
    "        \"pattern_completion\",      # Understanding natural language\n",
    "        \"knowledge_retrieval\",      # Medical knowledge\n",
    "        \"continuous_state\",         # Symptom timing\n",
    "        \"constraint_satisfaction\"   # Drug interactions\n",
    "    ]\n",
    ")\n",
    "\n",
    "classifier.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Code Assistant\n",
    "classifier2 = CapabilityClassifier()\n",
    "\n",
    "classification2 = classifier2.classify(\n",
    "    scenario_name=\"Code Completion Assistant\",\n",
    "    required_classes=[\n",
    "        \"pattern_completion\",       # Code patterns\n",
    "        \"knowledge_retrieval\",      # API knowledge\n",
    "        \"interactive_collaboration\" # Pair programming\n",
    "    ]\n",
    ")\n",
    "\n",
    "classifier2.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Exercise - Classify Your Deployment Scenario\n",
    "\n",
    "Use the framework below to classify your own LLM deployment scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR EXERCISE: Fill in your deployment scenario\n",
    "\n",
    "my_classifier = CapabilityClassifier()\n",
    "\n",
    "# Replace with your scenario\n",
    "my_classification = my_classifier.classify(\n",
    "    scenario_name=\"YOUR SCENARIO NAME HERE\",  # e.g., \"Customer Support Chatbot\"\n",
    "    required_classes=[\n",
    "        # Uncomment the classes your scenario requires:\n",
    "        \"pattern_completion\",\n",
    "        # \"knowledge_retrieval\",\n",
    "        # \"compositional_reasoning\",\n",
    "        # \"continuous_state\",\n",
    "        # \"constraint_satisfaction\",\n",
    "        # \"interactive_collaboration\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "my_classifier.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Key Takeaways\n",
    "\n",
    "1. **Not all tasks are equal.** LLMs excel at pattern completion but fail at continuous state representation and compositional reasoning.\n",
    "\n",
    "2. **Benchmarks lie.** High benchmark scores do not predict production reliability for tasks requiring capabilities beyond pattern matching.\n",
    "\n",
    "3. **Classify before building.** Understanding capability requirements prevents wasted engineering effort on fundamentally unsuitable applications.\n",
    "\n",
    "4. **Hybrid architectures are often necessary.** For high-stakes applications requiring Class 3-5 capabilities, pure LLM deployment is inappropriate.\n",
    "\n",
    "5. **Testing must match capability class.** Different failure modes require different testing protocols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "**Deliverable 1: Capability Classification Matrix**\n",
    "\n",
    "1. Choose a production LLM deployment scenario (your own or hypothetical)\n",
    "2. Complete the classification using the `CapabilityClassifier`\n",
    "3. For each required capability class, provide:\n",
    "   - Specific examples from your scenario\n",
    "   - Potential failure modes\n",
    "   - Risk assessment (Low/Medium/High/Critical)\n",
    "4. Determine if hybrid architecture is needed and why\n",
    "5. List all required testing protocols\n",
    "\n",
    "Submit your classification matrix as a PDF or Markdown document.\n",
    "\n",
    "---\n",
    "\n",
    "**Next Session:** Architectural Prerequisites for Reliable Performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
