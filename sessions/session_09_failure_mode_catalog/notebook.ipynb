{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Session 9: Failure Mode Catalog\n",
    "## Complete Taxonomy with Detection Protocols\n",
    "\n",
    "**Production LLM Deployment: Risk Characterization Before Failure**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Javihaus/Production_LLM_Deployment/blob/main/sessions/session_09_failure_mode_catalog/notebook.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "**Learning Objectives:**\n",
    "1. Apply the complete failure mode taxonomy\n",
    "2. Select appropriate detection protocols\n",
    "3. Build comprehensive testing suites\n",
    "4. Prioritize testing based on risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy pandas matplotlib seaborn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Part 1: Complete Failure Mode Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FailureMode:\n",
    "    name: str\n",
    "    description: str\n",
    "    detection_method: str\n",
    "    key_metric: str\n",
    "    threshold: str\n",
    "    risk_domains: List[str]\n",
    "\n",
    "\n",
    "FAILURE_MODES = [\n",
    "    FailureMode(\n",
    "        name=\"Brittleness\",\n",
    "        description=\"Accuracy varies with prompt format changes\",\n",
    "        detection_method=\"Multi-format testing (3+ formats per scenario)\",\n",
    "        key_metric=\"Max-min accuracy across formats\",\n",
    "        threshold=\">30pp = high brittleness\",\n",
    "        risk_domains=[\"All domains\"]\n",
    "    ),\n",
    "    FailureMode(\n",
    "        name=\"Action Bias\",\n",
    "        description=\"Systematically recommends action over inaction\",\n",
    "        detection_method=\"Balanced test sets (50% action, 50% no-action)\",\n",
    "        key_metric=\"False Positive Rate\",\n",
    "        threshold=\">20% FPR = significant bias\",\n",
    "        risk_domains=[\"Medical\", \"Safety\", \"Compliance\"]\n",
    "    ),\n",
    "    FailureMode(\n",
    "        name=\"Scaling Pathology\",\n",
    "        description=\"Larger models more confident but not more accurate\",\n",
    "        detection_method=\"Test across 3+ model sizes\",\n",
    "        key_metric=\"Confidence-Competence Gap (CCG)\",\n",
    "        threshold=\"CCG < -20 = pathological\",\n",
    "        risk_domains=[\"Temporal\", \"Compositional\", \"Constraint tasks\"]\n",
    "    ),\n",
    "    FailureMode(\n",
    "        name=\"Temporal Reasoning\",\n",
    "        description=\"Fails on time-based constraint tasks\",\n",
    "        detection_method=\"Allen's interval algebra test suite\",\n",
    "        key_metric=\"Temporal accuracy + FPR\",\n",
    "        threshold=\"<70% accuracy or >30% FPR\",\n",
    "        risk_domains=[\"Scheduling\", \"Medical timing\", \"Finance\"]\n",
    "    ),\n",
    "    FailureMode(\n",
    "        name=\"Latency Degradation\",\n",
    "        description=\"Response time impacts interaction quality\",\n",
    "        detection_method=\"Response time measurement\",\n",
    "        key_metric=\"Turns per minute / Task completion\",\n",
    "        threshold=\">5s average = significant impact\",\n",
    "        risk_domains=[\"Interactive\", \"Collaborative\", \"Real-time\"]\n",
    "    ),\n",
    "    FailureMode(\n",
    "        name=\"Hallucination\",\n",
    "        description=\"Generates plausible but false information\",\n",
    "        detection_method=\"Fact verification against ground truth\",\n",
    "        key_metric=\"Grounding rate / Factual accuracy\",\n",
    "        threshold=\"<90% for high-stakes applications\",\n",
    "        risk_domains=[\"Knowledge retrieval\", \"Medical\", \"Legal\"]\n",
    "    ),\n",
    "    FailureMode(\n",
    "        name=\"Compositional Failure\",\n",
    "        description=\"Cannot generalize to novel combinations\",\n",
    "        detection_method=\"Lake & Baroni style composition tests\",\n",
    "        key_metric=\"Novel combination accuracy\",\n",
    "        threshold=\"<50% = significant limitation\",\n",
    "        risk_domains=[\"Algorithm design\", \"Planning\", \"Reasoning\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Display catalog\n",
    "print(\"=\"*80)\n",
    "print(\"COMPLETE FAILURE MODE CATALOG\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for fm in FAILURE_MODES:\n",
    "    print(f\"\\n{fm.name}\")\n",
    "    print(f\"  Description: {fm.description}\")\n",
    "    print(f\"  Detection: {fm.detection_method}\")\n",
    "    print(f\"  Metric: {fm.key_metric}\")\n",
    "    print(f\"  Threshold: {fm.threshold}\")\n",
    "    print(f\"  Risk domains: {', '.join(fm.risk_domains)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Part 2: Testing Suite Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestingSuiteBuilder:\n",
    "    \"\"\"Build comprehensive pre-deployment testing suite.\"\"\"\n",
    "    \n",
    "    def __init__(self, application_name: str):\n",
    "        self.application = application_name\n",
    "        self.selected_modes = []\n",
    "        self.test_inventory = []\n",
    "    \n",
    "    def assess_applicability(self, domains: List[str]) -> List[FailureMode]:\n",
    "        \"\"\"Identify applicable failure modes based on domains.\"\"\"\n",
    "        applicable = []\n",
    "        for fm in FAILURE_MODES:\n",
    "            if \"All domains\" in fm.risk_domains:\n",
    "                applicable.append(fm)\n",
    "            elif any(d in fm.risk_domains for d in domains):\n",
    "                applicable.append(fm)\n",
    "        self.selected_modes = applicable\n",
    "        return applicable\n",
    "    \n",
    "    def generate_checklist(self) -> List[Dict]:\n",
    "        \"\"\"Generate testing checklist.\"\"\"\n",
    "        checklist = []\n",
    "        for fm in self.selected_modes:\n",
    "            checklist.append({\n",
    "                \"Failure Mode\": fm.name,\n",
    "                \"Test Method\": fm.detection_method,\n",
    "                \"Metric\": fm.key_metric,\n",
    "                \"Pass Criteria\": fm.threshold,\n",
    "                \"Status\": \"Pending\"\n",
    "            })\n",
    "        return checklist\n",
    "    \n",
    "    def print_suite(self):\n",
    "        \"\"\"Print the testing suite.\"\"\"\n",
    "        checklist = self.generate_checklist()\n",
    "        df = pd.DataFrame(checklist)\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        print(f\"PRE-DEPLOYMENT TESTING SUITE: {self.application}\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\nApplicable failure modes: {len(self.selected_modes)}\")\n",
    "        print(\"\\n\" + df.to_string(index=False))\n",
    "\n",
    "\n",
    "# Example: Medical Triage Application\n",
    "builder = TestingSuiteBuilder(\"Medical Symptom Triage\")\n",
    "applicable = builder.assess_applicability([\"Medical\", \"Safety\", \"Interactive\"])\n",
    "builder.print_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Part 3: Prioritization Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk prioritization\n",
    "priority_matrix = {\n",
    "    \"Failure Mode\": [fm.name for fm in FAILURE_MODES],\n",
    "    \"Medical\": [5, 5, 3, 5, 3, 5, 2],\n",
    "    \"Financial\": [4, 4, 3, 4, 2, 5, 3],\n",
    "    \"Customer Service\": [4, 2, 2, 2, 4, 3, 2],\n",
    "    \"Code Assistant\": [3, 2, 2, 1, 4, 3, 4],\n",
    "}\n",
    "\n",
    "df_priority = pd.DataFrame(priority_matrix)\n",
    "df_priority = df_priority.set_index(\"Failure Mode\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(df_priority, annot=True, cmap=\"YlOrRd\", ax=ax,\n",
    "            cbar_kws={\"label\": \"Priority (1-5)\"})\n",
    "ax.set_title(\"Failure Mode Priority by Application Domain\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPriority Scale: 1 = Low priority, 5 = Critical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Part 4: Exercise - Build Your Testing Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR EXERCISE: Build your testing suite\n",
    "\n",
    "my_builder = TestingSuiteBuilder(\"YOUR APPLICATION NAME\")\n",
    "\n",
    "# Select your applicable domains:\n",
    "my_domains = [\n",
    "    # Uncomment applicable domains:\n",
    "    # \"Medical\",\n",
    "    # \"Safety\",\n",
    "    # \"Financial\",\n",
    "    # \"Scheduling\",\n",
    "    # \"Interactive\",\n",
    "    # \"Knowledge retrieval\",\n",
    "    # \"Planning\",\n",
    "]\n",
    "\n",
    "if my_domains:\n",
    "    my_applicable = my_builder.assess_applicability(my_domains)\n",
    "    my_builder.print_suite()\n",
    "else:\n",
    "    print(\"Please uncomment your applicable domains above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Use the complete taxonomy.** Don't cherry-pick failure modes to test.\n",
    "\n",
    "2. **Prioritize by domain risk.** Medical/safety applications need more rigorous testing.\n",
    "\n",
    "3. **Document everything.** Testing results are part of deployment documentation.\n",
    "\n",
    "4. **Define pass/fail criteria upfront.** Avoid moving goalposts after testing.\n",
    "\n",
    "---\n",
    "\n",
    "**Next Session:** Hybrid Architecture Design I"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
