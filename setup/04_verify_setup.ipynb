{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Verification Notebook\n",
    "\n",
    "## Production LLM Deployment: Risk Characterization Before Failure\n",
    "\n",
    "Run this notebook to verify your environment is correctly configured for the course.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Javihaus/Production_LLM_Deployment/blob/main/setup/04_verify_setup.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q anthropic langchain langgraph langchain-anthropic langsmith\n",
    "!pip install -q numpy pandas scipy matplotlib seaborn statsmodels\n",
    "!pip install -q tqdm\n",
    "\n",
    "print(\"Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Verify Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Core LLM packages\n",
    "packages_to_check = [\n",
    "    ('anthropic', 'Anthropic SDK'),\n",
    "    ('langchain', 'LangChain'),\n",
    "    ('langgraph', 'LangGraph'),\n",
    "    ('numpy', 'NumPy'),\n",
    "    ('pandas', 'Pandas'),\n",
    "    ('scipy', 'SciPy'),\n",
    "    ('matplotlib', 'Matplotlib'),\n",
    "    ('seaborn', 'Seaborn'),\n",
    "    ('statsmodels', 'Statsmodels'),\n",
    "]\n",
    "\n",
    "all_passed = True\n",
    "for package, name in packages_to_check:\n",
    "    try:\n",
    "        module = __import__(package)\n",
    "        version = getattr(module, '__version__', 'installed')\n",
    "        print(f\"OK {name}: {version}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"FAIL {name}: Not installed - {e}\")\n",
    "        all_passed = False\n",
    "\n",
    "print(\"=\"*50)\n",
    "if all_passed:\n",
    "    print(\"All packages verified successfully!\")\n",
    "else:\n",
    "    print(\"Some packages are missing. Re-run Step 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure API Key\n",
    "\n",
    "### For Google Colab:\n",
    "1. Click the **key icon** (ðŸ”‘) in the left sidebar\n",
    "2. Add a secret named `ANTHROPIC_API_KEY`\n",
    "3. Paste your API key and enable notebook access\n",
    "\n",
    "### For Local Environment:\n",
    "Set the `ANTHROPIC_API_KEY` environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Try to get API key from Colab secrets first, then environment\n",
    "api_key = None\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    api_key = userdata.get('ANTHROPIC_API_KEY')\n",
    "    print(\"API key loaded from Colab secrets\")\n",
    "except:\n",
    "    api_key = os.environ.get('ANTHROPIC_API_KEY')\n",
    "    if api_key:\n",
    "        print(\"API key loaded from environment variable\")\n",
    "\n",
    "if api_key:\n",
    "    print(f\"API Key: {'*' * 20}...{api_key[-4:]}\")\n",
    "    print(f\"Length: {len(api_key)} characters\")\n",
    "else:\n",
    "    print(\"WARNING: No API key found!\")\n",
    "    print(\"Please configure your ANTHROPIC_API_KEY before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test Anthropic API Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "# Initialize client\n",
    "if api_key:\n",
    "    client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "    try:\n",
    "        # Simple test message\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-sonnet-4-5-20250929\",\n",
    "            max_tokens=100,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Respond with exactly: 'API connection successful! Ready for Production LLM Deployment course.'\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(\"API Response:\")\n",
    "        print(response.content[0].text)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Model: {response.model}\")\n",
    "        print(f\"Input tokens: {response.usage.input_tokens}\")\n",
    "        print(f\"Output tokens: {response.usage.output_tokens}\")\n",
    "\n",
    "        # Estimate cost\n",
    "        input_cost = response.usage.input_tokens * 3 / 1_000_000\n",
    "        output_cost = response.usage.output_tokens * 15 / 1_000_000\n",
    "        print(f\"Estimated cost: ${input_cost + output_cost:.6f}\")\n",
    "        print(\"\\nAPI test passed!\")\n",
    "\n",
    "    except anthropic.AuthenticationError:\n",
    "        print(\"ERROR: Invalid API key. Please check your key and try again.\")\n",
    "    except anthropic.RateLimitError:\n",
    "        print(\"ERROR: Rate limit exceeded. Wait a moment and try again.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {type(e).__name__}: {e}\")\n",
    "else:\n",
    "    print(\"Skipping API test - no API key configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test LangChain Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "if api_key:\n",
    "    try:\n",
    "        # Initialize LangChain with Claude\n",
    "        llm = ChatAnthropic(\n",
    "            model=\"claude-sonnet-4-5-20250929\",\n",
    "            api_key=api_key,\n",
    "            max_tokens=100\n",
    "        )\n",
    "\n",
    "        # Test invocation\n",
    "        response = llm.invoke([HumanMessage(content=\"Say 'LangChain integration working!' only.\")])\n",
    "        print(f\"LangChain Response: {response.content}\")\n",
    "        print(\"\\nLangChain test passed!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {type(e).__name__}: {e}\")\n",
    "else:\n",
    "    print(\"Skipping LangChain test - no API key configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test Statistical Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "group_a = np.random.normal(0.75, 0.1, 30)  # Higher accuracy\n",
    "group_b = np.random.normal(0.45, 0.15, 30)  # Lower accuracy\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_value = stats.ttest_ind(group_a, group_b)\n",
    "\n",
    "print(\"Statistical Test Results:\")\n",
    "print(f\"  Group A mean: {group_a.mean():.3f} (SD: {group_a.std():.3f})\")\n",
    "print(f\"  Group B mean: {group_b.mean():.3f} (SD: {group_b.std():.3f})\")\n",
    "print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "print(f\"  Significant difference: {p_value < 0.05}\")\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Box plot\n",
    "data = pd.DataFrame({'Group A': group_a, 'Group B': group_b})\n",
    "data_melted = data.melt(var_name='Group', value_name='Accuracy')\n",
    "sns.boxplot(data=data_melted, x='Group', y='Accuracy', ax=axes[0])\n",
    "axes[0].set_title('Accuracy Distribution by Group')\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Distribution plot\n",
    "sns.histplot(group_a, kde=True, label='Group A', alpha=0.5, ax=axes[1])\n",
    "sns.histplot(group_b, kde=True, label='Group B', alpha=0.5, ax=axes[1])\n",
    "axes[1].set_title('Accuracy Distributions')\n",
    "axes[1].set_xlabel('Accuracy')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStatistical libraries test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Verify Google Drive Access (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Create course directory\n",
    "# !mkdir -p /content/drive/MyDrive/LLM_Course\n",
    "# print(\"Course directory created at /content/drive/MyDrive/LLM_Course\")\n",
    "\n",
    "print(\"Google Drive mounting available (uncomment to enable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SETUP VERIFICATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checks = [\n",
    "    (\"Python 3.10+\", sys.version_info >= (3, 10)),\n",
    "    (\"Core packages installed\", all_passed if 'all_passed' in dir() else False),\n",
    "    (\"API key configured\", api_key is not None),\n",
    "]\n",
    "\n",
    "for check_name, passed in checks:\n",
    "    status = \"PASS\" if passed else \"FAIL\"\n",
    "    print(f\"  [{status}] {check_name}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "if all(passed for _, passed in checks):\n",
    "    print(\"\\nAll checks passed! You're ready for the course.\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  1. Review the course syllabus (SYLLABUS.md)\")\n",
    "    print(\"  2. Complete pre-course reading\")\n",
    "    print(\"  3. Identify your deployment scenario for exercises\")\n",
    "    print(\"  4. Join the course Slack workspace\")\n",
    "else:\n",
    "    print(\"\\nSome checks failed. Please resolve issues before Session 1.\")\n",
    "    print(\"\\nNeed help? Contact: javier@jmarin.info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### API Key Issues\n",
    "- Verify key starts with `sk-ant-api03-`\n",
    "- Check for extra spaces when copying\n",
    "- Ensure payment method is configured in Anthropic Console\n",
    "\n",
    "### Package Installation Issues\n",
    "- Try restarting runtime and re-running Step 1\n",
    "- For Colab: Runtime > Restart runtime\n",
    "\n",
    "### Connection Issues\n",
    "- Check internet connection\n",
    "- Verify Anthropic API status: https://status.anthropic.com\n",
    "\n",
    "---\n",
    "\n",
    "**Course:** Production LLM Deployment: Risk Characterization Before Failure  \n",
    "**Instructor:** Javier MarÃ­n  \n",
    "**Contact:** javier@jmarin.info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
